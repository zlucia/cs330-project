{"num_evals_since_improvement": 0, "train_state": {"global_steps": 29, "task_steps": {"abstract_algebra_test": 2, "anatomy_test": 1, "astronomy_test": 1, "business_ethics_test": 0, "clinical_knowledge_test": 0, "college_biology_test": 1, "college_chemistry_test": 1, "college_computer_science_test": 0, "college_mathematics_test": 1, "college_medicine_test": 0, "college_physics_test": 1, "computer_security_test": 0, "conceptual_physics_test": 0, "econometrics_test": 0, "electrical_engineering_test": 1, "elementary_mathematics_test": 0, "formal_logic_test": 1, "global_facts_test": 0, "high_school_biology_test": 1, "high_school_chemistry_test": 0, "high_school_computer_science_test": 1, "high_school_european_history_test": 2, "high_school_geography_test": 0, "high_school_government_and_politics_test": 2, "high_school_macroeconomics_test": 1, "high_school_mathematics_test": 1, "high_school_microeconomics_test": 0, "high_school_physics_test": 0, "high_school_psychology_test": 0, "high_school_statistics_test": 0, "high_school_us_history_test": 0, "high_school_world_history_test": 0, "human_aging_test": 0, "human_sexuality_test": 2, "international_law_test": 1, "jurisprudence_test": 0, "logical_fallacies_test": 0, "machine_learning_test": 0, "management_test": 0, "marketing_test": 0, "medical_genetics_test": 1, "miscellaneous_test": 0, "moral_disputes_test": 0, "moral_scenarios_test": 0, "nutrition_test": 0, "philosophy_test": 0, "prehistory_test": 0, "professional_accounting_test": 1, "professional_law_test": 1, "professional_medicine_test": 0, "professional_psychology_test": 0, "public_relations_test": 0, "security_studies_test": 1, "sociology_test": 1, "us_foreign_policy_test": 1, "virology_test": 0, "world_religions_test": 2}}, "TIMESTAMP": 1638760312.906017}
{"num_evals_since_improvement": 0, "train_state": {"global_steps": 59, "task_steps": {"abstract_algebra_test": 2, "anatomy_test": 2, "astronomy_test": 1, "business_ethics_test": 1, "clinical_knowledge_test": 2, "college_biology_test": 2, "college_chemistry_test": 2, "college_computer_science_test": 1, "college_mathematics_test": 1, "college_medicine_test": 0, "college_physics_test": 1, "computer_security_test": 0, "conceptual_physics_test": 0, "econometrics_test": 0, "electrical_engineering_test": 1, "elementary_mathematics_test": 1, "formal_logic_test": 2, "global_facts_test": 0, "high_school_biology_test": 1, "high_school_chemistry_test": 1, "high_school_computer_science_test": 1, "high_school_european_history_test": 2, "high_school_geography_test": 0, "high_school_government_and_politics_test": 3, "high_school_macroeconomics_test": 2, "high_school_mathematics_test": 1, "high_school_microeconomics_test": 1, "high_school_physics_test": 0, "high_school_psychology_test": 0, "high_school_statistics_test": 0, "high_school_us_history_test": 1, "high_school_world_history_test": 2, "human_aging_test": 0, "human_sexuality_test": 3, "international_law_test": 1, "jurisprudence_test": 1, "logical_fallacies_test": 0, "machine_learning_test": 2, "management_test": 1, "marketing_test": 1, "medical_genetics_test": 1, "miscellaneous_test": 1, "moral_disputes_test": 0, "moral_scenarios_test": 1, "nutrition_test": 0, "philosophy_test": 1, "prehistory_test": 0, "professional_accounting_test": 1, "professional_law_test": 2, "professional_medicine_test": 1, "professional_psychology_test": 0, "public_relations_test": 0, "security_studies_test": 1, "sociology_test": 2, "us_foreign_policy_test": 3, "virology_test": 0, "world_religions_test": 2}}, "TIMESTAMP": 1638760533.0641265}
{"num_evals_since_improvement": 0, "train_state": {"global_steps": 89, "task_steps": {"abstract_algebra_test": 2, "anatomy_test": 2, "astronomy_test": 1, "business_ethics_test": 1, "clinical_knowledge_test": 2, "college_biology_test": 2, "college_chemistry_test": 2, "college_computer_science_test": 2, "college_mathematics_test": 1, "college_medicine_test": 1, "college_physics_test": 1, "computer_security_test": 1, "conceptual_physics_test": 1, "econometrics_test": 2, "electrical_engineering_test": 1, "elementary_mathematics_test": 2, "formal_logic_test": 2, "global_facts_test": 0, "high_school_biology_test": 2, "high_school_chemistry_test": 1, "high_school_computer_science_test": 3, "high_school_european_history_test": 2, "high_school_geography_test": 1, "high_school_government_and_politics_test": 3, "high_school_macroeconomics_test": 2, "high_school_mathematics_test": 2, "high_school_microeconomics_test": 2, "high_school_physics_test": 1, "high_school_psychology_test": 0, "high_school_statistics_test": 2, "high_school_us_history_test": 1, "high_school_world_history_test": 2, "human_aging_test": 2, "human_sexuality_test": 3, "international_law_test": 1, "jurisprudence_test": 1, "logical_fallacies_test": 1, "machine_learning_test": 2, "management_test": 2, "marketing_test": 2, "medical_genetics_test": 1, "miscellaneous_test": 1, "moral_disputes_test": 2, "moral_scenarios_test": 2, "nutrition_test": 2, "philosophy_test": 1, "prehistory_test": 2, "professional_accounting_test": 2, "professional_law_test": 2, "professional_medicine_test": 1, "professional_psychology_test": 0, "public_relations_test": 0, "security_studies_test": 1, "sociology_test": 2, "us_foreign_policy_test": 3, "virology_test": 0, "world_religions_test": 3}}, "TIMESTAMP": 1638760695.930809}
{"num_evals_since_improvement": 1, "train_state": {"global_steps": 119, "task_steps": {"abstract_algebra_test": 3, "anatomy_test": 2, "astronomy_test": 2, "business_ethics_test": 3, "clinical_knowledge_test": 2, "college_biology_test": 2, "college_chemistry_test": 2, "college_computer_science_test": 2, "college_mathematics_test": 2, "college_medicine_test": 3, "college_physics_test": 1, "computer_security_test": 1, "conceptual_physics_test": 2, "econometrics_test": 2, "electrical_engineering_test": 1, "elementary_mathematics_test": 2, "formal_logic_test": 2, "global_facts_test": 0, "high_school_biology_test": 2, "high_school_chemistry_test": 2, "high_school_computer_science_test": 3, "high_school_european_history_test": 2, "high_school_geography_test": 2, "high_school_government_and_politics_test": 3, "high_school_macroeconomics_test": 3, "high_school_mathematics_test": 2, "high_school_microeconomics_test": 3, "high_school_physics_test": 3, "high_school_psychology_test": 2, "high_school_statistics_test": 3, "high_school_us_history_test": 2, "high_school_world_history_test": 2, "human_aging_test": 2, "human_sexuality_test": 3, "international_law_test": 1, "jurisprudence_test": 2, "logical_fallacies_test": 3, "machine_learning_test": 2, "management_test": 2, "marketing_test": 2, "medical_genetics_test": 2, "miscellaneous_test": 2, "moral_disputes_test": 2, "moral_scenarios_test": 2, "nutrition_test": 3, "philosophy_test": 1, "prehistory_test": 2, "professional_accounting_test": 2, "professional_law_test": 2, "professional_medicine_test": 2, "professional_psychology_test": 1, "public_relations_test": 0, "security_studies_test": 2, "sociology_test": 2, "us_foreign_policy_test": 3, "virology_test": 2, "world_religions_test": 4}}, "TIMESTAMP": 1638760862.1422608}
{"num_evals_since_improvement": 2, "train_state": {"global_steps": 149, "task_steps": {"abstract_algebra_test": 3, "anatomy_test": 2, "astronomy_test": 3, "business_ethics_test": 3, "clinical_knowledge_test": 3, "college_biology_test": 2, "college_chemistry_test": 2, "college_computer_science_test": 2, "college_mathematics_test": 2, "college_medicine_test": 3, "college_physics_test": 2, "computer_security_test": 2, "conceptual_physics_test": 2, "econometrics_test": 4, "electrical_engineering_test": 3, "elementary_mathematics_test": 3, "formal_logic_test": 3, "global_facts_test": 1, "high_school_biology_test": 3, "high_school_chemistry_test": 3, "high_school_computer_science_test": 3, "high_school_european_history_test": 3, "high_school_geography_test": 3, "high_school_government_and_politics_test": 3, "high_school_macroeconomics_test": 3, "high_school_mathematics_test": 2, "high_school_microeconomics_test": 3, "high_school_physics_test": 3, "high_school_psychology_test": 3, "high_school_statistics_test": 3, "high_school_us_history_test": 2, "high_school_world_history_test": 2, "human_aging_test": 3, "human_sexuality_test": 3, "international_law_test": 2, "jurisprudence_test": 2, "logical_fallacies_test": 3, "machine_learning_test": 4, "management_test": 2, "marketing_test": 3, "medical_genetics_test": 2, "miscellaneous_test": 2, "moral_disputes_test": 3, "moral_scenarios_test": 2, "nutrition_test": 3, "philosophy_test": 2, "prehistory_test": 2, "professional_accounting_test": 3, "professional_law_test": 2, "professional_medicine_test": 3, "professional_psychology_test": 3, "public_relations_test": 2, "security_studies_test": 2, "sociology_test": 3, "us_foreign_policy_test": 3, "virology_test": 2, "world_religions_test": 4}}, "TIMESTAMP": 1638761039.9024196}
{"num_evals_since_improvement": 3, "train_state": {"global_steps": 171, "task_steps": {"abstract_algebra_test": 3, "anatomy_test": 2, "astronomy_test": 3, "business_ethics_test": 3, "clinical_knowledge_test": 3, "college_biology_test": 3, "college_chemistry_test": 3, "college_computer_science_test": 3, "college_mathematics_test": 2, "college_medicine_test": 3, "college_physics_test": 2, "computer_security_test": 2, "conceptual_physics_test": 2, "econometrics_test": 4, "electrical_engineering_test": 3, "elementary_mathematics_test": 3, "formal_logic_test": 3, "global_facts_test": 2, "high_school_biology_test": 3, "high_school_chemistry_test": 3, "high_school_computer_science_test": 3, "high_school_european_history_test": 3, "high_school_geography_test": 3, "high_school_government_and_politics_test": 3, "high_school_macroeconomics_test": 3, "high_school_mathematics_test": 3, "high_school_microeconomics_test": 4, "high_school_physics_test": 3, "high_school_psychology_test": 3, "high_school_statistics_test": 3, "high_school_us_history_test": 3, "high_school_world_history_test": 2, "human_aging_test": 3, "human_sexuality_test": 3, "international_law_test": 4, "jurisprudence_test": 2, "logical_fallacies_test": 3, "machine_learning_test": 4, "management_test": 4, "marketing_test": 3, "medical_genetics_test": 3, "miscellaneous_test": 4, "moral_disputes_test": 3, "moral_scenarios_test": 3, "nutrition_test": 3, "philosophy_test": 3, "prehistory_test": 3, "professional_accounting_test": 4, "professional_law_test": 2, "professional_medicine_test": 3, "professional_psychology_test": 5, "public_relations_test": 3, "security_studies_test": 3, "sociology_test": 3, "us_foreign_policy_test": 3, "virology_test": 2, "world_religions_test": 4}}, "TIMESTAMP": 1638761190.911111}
{"num_evals_since_improvement": 4, "train_state": {"global_steps": 171, "task_steps": {"abstract_algebra_test": 3, "anatomy_test": 2, "astronomy_test": 3, "business_ethics_test": 3, "clinical_knowledge_test": 3, "college_biology_test": 3, "college_chemistry_test": 3, "college_computer_science_test": 3, "college_mathematics_test": 2, "college_medicine_test": 3, "college_physics_test": 2, "computer_security_test": 2, "conceptual_physics_test": 2, "econometrics_test": 4, "electrical_engineering_test": 3, "elementary_mathematics_test": 3, "formal_logic_test": 3, "global_facts_test": 2, "high_school_biology_test": 3, "high_school_chemistry_test": 3, "high_school_computer_science_test": 3, "high_school_european_history_test": 3, "high_school_geography_test": 3, "high_school_government_and_politics_test": 3, "high_school_macroeconomics_test": 3, "high_school_mathematics_test": 3, "high_school_microeconomics_test": 4, "high_school_physics_test": 3, "high_school_psychology_test": 3, "high_school_statistics_test": 3, "high_school_us_history_test": 3, "high_school_world_history_test": 2, "human_aging_test": 3, "human_sexuality_test": 3, "international_law_test": 4, "jurisprudence_test": 2, "logical_fallacies_test": 3, "machine_learning_test": 4, "management_test": 4, "marketing_test": 3, "medical_genetics_test": 3, "miscellaneous_test": 4, "moral_disputes_test": 3, "moral_scenarios_test": 3, "nutrition_test": 3, "philosophy_test": 3, "prehistory_test": 3, "professional_accounting_test": 4, "professional_law_test": 2, "professional_medicine_test": 3, "professional_psychology_test": 5, "public_relations_test": 3, "security_studies_test": 3, "sociology_test": 3, "us_foreign_policy_test": 3, "virology_test": 2, "world_religions_test": 4}}, "TIMESTAMP": 1638761236.5401535}
